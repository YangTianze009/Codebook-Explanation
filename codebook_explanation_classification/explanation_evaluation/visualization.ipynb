{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token mask label level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import csv\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import csv\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "data = \"generated\"\n",
    "\n",
    "\n",
    "def preprocess(img, target_image_size=256):\n",
    "    s = min(img.size)\n",
    "    if s < target_image_size:\n",
    "        raise ValueError(f'Min dimension for image {s} < {target_image_size}')\n",
    "    r = target_image_size / s\n",
    "    s = (round(r * img.size[1]), round(r * img.size[0]))\n",
    "    img = TF.resize(img, s, interpolation=Image.LANCZOS)\n",
    "    img = TF.center_crop(img, output_size=2 * [target_image_size])\n",
    "    img = torch.unsqueeze(T.ToTensor()(img), 0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_top_tokens_baseline(input_csv, top_n):\n",
    "    # 存储Token和Count的列表\n",
    "    tokens = []\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    with open(input_csv, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            token = int(row['Token'])  # 读取Token\n",
    "            count = int(row['Count'])  # 读取Count\n",
    "            tokens.append((token, count))  # 将Token和Count存入列表\n",
    "    \n",
    "    # 按照Count降序排序\n",
    "    tokens.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # 获取前N个Token\n",
    "    top_n_tokens = [token for token, _ in tokens[:top_n]]\n",
    "    \n",
    "    return top_n_tokens\n",
    "\n",
    "def load_top_tokens(csv_path, top_n, token_number):\n",
    "    target_token_list = []\n",
    "    \"\"\"\n",
    "    从指定的csv文件中加载Top N的某一行token及其对应的文件列表。\n",
    "\n",
    "    参数:\n",
    "    csv_path (str): 要读取的csv文件路径。\n",
    "    top_n (int): 要查询的Top N级别（如1, 5, 10, 20）。\n",
    "    row_num (int): 要查询的行号（从1开始，排除表头）。\n",
    "\n",
    "    返回:\n",
    "    token (str): 对应的token索引。\n",
    "    files (list): 对应的文件列表。\n",
    "    \"\"\"\n",
    "    with open(csv_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        in_top_n_section = False\n",
    "        current_row = 0\n",
    "\n",
    "        for row in reader:\n",
    "            # 检查是否到了Top N的部分\n",
    "            if f\"Top {top_n} Tokens\" in row:\n",
    "                in_top_n_section = True\n",
    "                next(reader)\n",
    "                current_row = 0\n",
    "                continue\n",
    "\n",
    "            # 如果到了Top N部分，开始读取指定行\n",
    "            if in_top_n_section:\n",
    "                if \"Top\" in row[0] or current_row == token_number:\n",
    "                    break\n",
    "                token = int(row[0])  # 获取token索引\n",
    "                files = row[2].split('; ')  # 获取文件名列表，并按分号分割\n",
    "                target_token_list.append(token)\n",
    "                current_row += 1\n",
    "\n",
    "    return target_token_list  # 如果未找到，则返回None\n",
    "\n",
    "\n",
    "# 提供要查找的特定 token\n",
    "target_label = 83  # 替换为你要查找的token索引\n",
    "\n",
    "# # 提供要处理的npy文件名列表\n",
    "\n",
    "if data == \"generated\":\n",
    "    csv_path = f\"/data2/ty45972_data2/taming-transformers/codebook_explanation_classification/results/Explanation/generated_data/label/Net1/label_activation_statistics/label_{target_label}.csv\"\n",
    "    test_csv = f\"/data2/ty45972_data2/taming-transformers/codebook_explanation_classification/datasets/VQGAN_16384_generated_new/test_embeddings.csv\"\n",
    "    image_base_path = '/data2/ty45972_data2/taming-transformers/datasets/imagenet_VQGAN_generated/'\n",
    "    baseline_path = f\"/data2/ty45972_data2/taming-transformers/codebook_explanation_classification/results/Explanation/baseline_statistics/label_{target_label}.csv\"\n",
    "    with open('/data2/ty45972_data2/taming-transformers/codebook_explanation_classification/datasets/VQGAN_16384_generated_new/test_token_indices.pkl', 'rb') as f:\n",
    "        token_dict = pickle.load(f)\n",
    "\n",
    "# elif data == \"original\":\n",
    "#     csv_path = f\"/data2/ty45972_data2/taming-transformers/codebook_explanation_classification/results/Explanation/original_data/label/Net1/label_activation_statistics/label_{target_label}.csv\"\n",
    "#     activation_results_path = f\"/data2/ty45972_data2/taming-transformers/codebook_explanation_classification/results/Explanation/original_data/label/Net1/label_activation_results/label_{target_label}.csv\"\n",
    "#     image_base_path = \"/data2/ty45972_data2/taming-transformers/datasets/imagenet/train\"\n",
    "#     with open('/data2/ty45972_data2/taming-transformers/codebook_explanation_classification/datasets/VQGAN_16384_original/train_token_indices.pkl', 'rb') as f:\n",
    "#         token_dict = pickle.load(f)\n",
    "\n",
    "top_n = 20  # 表示查找Top n Tokens\n",
    "token_num = 50  # 查找第1行的token及其文件列表\n",
    "\n",
    "\n",
    "target_token_list = load_top_tokens(csv_path, top_n, token_num)\n",
    "target_token_list_baseline = load_top_tokens_baseline(baseline_path, token_num)\n",
    "print(f\"baseline token list is {target_token_list_baseline}\")\n",
    "\n",
    "if target_token_list:\n",
    "    print(f\"target token list is {len(target_token_list)}\")\n",
    "else:\n",
    "    print(\"Cannot find the specific token\")\n",
    "\n",
    "npy_file_list = []\n",
    "with open(test_csv, 'r', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)  # 跳过表头\n",
    "    \n",
    "    # 遍历CSV文件的每一行\n",
    "    for row in reader:\n",
    "        filename = row[0]  # 获取filename列（第1列）\n",
    "        label = int(row[1])     # 获取label列（第2列）\n",
    "        \n",
    "        # 如果label是指定的label，则将filename添加到列表中\n",
    "        if label == target_label:\n",
    "            npy_file_list.append(filename)\n",
    "print(f\"npy_file_list is {len(npy_file_list)}\")\n",
    "# 定义每个图像的token网格大小，假设为16x16\n",
    "grid_size = 16\n",
    "image_size = 256\n",
    "patch_size = image_size // grid_size\n",
    "\n",
    "def visualize_token_on_image(npy_filename, token_dict, target_token_list):\n",
    "    # 提取子文件夹和图片名信息\n",
    "    subfolder, image_name = npy_filename.split('_')\n",
    "    image_name = image_name.replace('.npy', '.png')\n",
    "    \n",
    "    # 构建图像路径\n",
    "    if data == \"generated\":\n",
    "        image_path = os.path.join(image_base_path, subfolder, image_name)\n",
    "    elif data == \"original\":\n",
    "        image_path = os.path.join(image_base_path, subfolder, npy_filename.replace(\".npy\", \".JPEG\"))\n",
    "    \n",
    "    print(f\"Image path is {image_path}\")\n",
    "    # 检查文件是否存在\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image {image_path} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # 打开图像\n",
    "    image = Image.open(image_path)\n",
    "    if data == \"original\":\n",
    "        processed_img = preprocess(image)\n",
    "        processed_img_pil = Image.fromarray((processed_img.squeeze(0).permute(1, 2, 0).numpy() * 255).astype(np.uint8))\n",
    "        image = processed_img_pil\n",
    "    \n",
    "    # 获取该文件对应的 token 列表\n",
    "    token_list = token_dict.get(npy_filename)\n",
    "    \n",
    "    if token_list is None:\n",
    "        print(f\"No token list found for {npy_filename}.\")\n",
    "        return\n",
    "    \n",
    "    # 查找目标 token 的所有索引位置\n",
    "    token_positions = [i for i, token in enumerate(token_list) if token in target_token_list]\n",
    "\n",
    "    \n",
    "\n",
    "    # 在图像上mask掉每个目标token的位置\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for token_position in token_positions:\n",
    "        row = token_position // grid_size\n",
    "        col = token_position % grid_size\n",
    "        \n",
    "        # 计算token在原图中的坐标\n",
    "        left = col * patch_size\n",
    "        upper = row * patch_size\n",
    "        right = left + patch_size\n",
    "        lower = upper + patch_size\n",
    "        \n",
    "        # 用黑色填充这些区域，表示mask\n",
    "        draw.rectangle([left, upper, right, lower], fill=(0, 0, 0))\n",
    "    \n",
    "    # 可视化图像\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"token list\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 遍历所有 npy 文件，进行可视化\n",
    "\n",
    "for i, npy_file in enumerate(npy_file_list):\n",
    "    visualize_token_on_image(npy_file, token_dict, target_token_list_baseline)\n",
    "    if i > 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Token indice pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "def load_token_indices(embedding_csv_path):\n",
    "    # 生成保存token indices的文件名\n",
    "    token_indices_save_path = embedding_csv_path.replace(\"test_embeddings.csv\", \"test_token_indices.pkl\")\n",
    "    \n",
    "    # 检查是否已经存在保存的token_indices文件\n",
    "    if os.path.exists(token_indices_save_path):\n",
    "        print(f\"Loading token indices from {token_indices_save_path}\")\n",
    "        with open(token_indices_save_path, 'rb') as f:\n",
    "            token_indices_dict = pickle.load(f)\n",
    "        return token_indices_dict\n",
    "    \n",
    "    # 如果没有保存的token_indices文件，就进行处理\n",
    "    print(f\"Processing token indices from {embedding_csv_path}\")\n",
    "    token_indices_dict = {}\n",
    "\n",
    "    # 先计算文件中的总行数，以便显示进度条\n",
    "    with open(embedding_csv_path, 'r') as infile:\n",
    "        total_lines = sum(1 for _ in infile) - 1  # 减去header行\n",
    "\n",
    "    # 重新打开文件并读取内容，同时显示进度条\n",
    "    with open(embedding_csv_path, 'r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        next(reader)  # 跳过header\n",
    "        for row in tqdm(reader, total=total_lines, desc=\"Loading token indices\"):\n",
    "            npy_file = row[0]\n",
    "            token_indices = ast.literal_eval(row[2])\n",
    "            token_indices_dict[npy_file] = token_indices\n",
    "    \n",
    "    # 保存处理后的token_indices_dict\n",
    "    with open(token_indices_save_path, 'wb') as f:\n",
    "        pickle.dump(token_indices_dict, f)\n",
    "    print(f\"Token indices saved to {token_indices_save_path}\")\n",
    "    \n",
    "    return token_indices_dict\n",
    "\n",
    "embedding_csv_path = \"/data2/ty45972_data2/taming-transformers/codebook_explanation_classification/datasets/VQGAN_16384_generated_new/test_embeddings.csv\"\n",
    "token_indices_dict = load_token_indices(embedding_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/myid/ty45972/miniconda3/envs/VQGAN/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/myid/ty45972/miniconda3/envs/VQGAN/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_32_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_32_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline token list is [4815, 10227, 11456, 11718, 12618, 7749, 948, 13670, 13291, 7504, 6172, 7467, 14447, 14703, 13909, 6965, 9470, 6523, 5772, 4493, 12159, 11004, 5722, 6805, 601, 1304, 10627, 10278, 12016, 11196, 11147, 8867, 15523, 14247, 12623, 6628, 774, 11591, 6783, 3932, 7771, 4945, 14037, 2528, 14975, 3812, 2127, 6690, 6386, 2255]\n",
      "target token list is 50\n",
      "npy_file_list is 50\n",
      "Image path is /data2/ty45972_data2/taming-transformers/datasets/imagenet_VQGAN_generated/83/001300.png\n",
      "Original logits for target label: 8.720815658569336\n",
      "Masked logits for target label: 6.315000057220459\n",
      "Difference in logits for target label: 2.405815601348877\n",
      "==================================================\n",
      "Image path is /data2/ty45972_data2/taming-transformers/datasets/imagenet_VQGAN_generated/83/001301.png\n",
      "Original logits for target label: 8.419610977172852\n",
      "Masked logits for target label: 3.4305028915405273\n",
      "Difference in logits for target label: 4.989108085632324\n",
      "==================================================\n",
      "Image path is /data2/ty45972_data2/taming-transformers/datasets/imagenet_VQGAN_generated/83/001302.png\n",
      "Original logits for target label: 9.060774803161621\n",
      "Masked logits for target label: 9.200052261352539\n",
      "Difference in logits for target label: -0.13927745819091797\n",
      "==================================================\n",
      "Image path is /data2/ty45972_data2/taming-transformers/datasets/imagenet_VQGAN_generated/83/001303.png\n",
      "Original logits for target label: 9.717551231384277\n",
      "Masked logits for target label: 9.886284828186035\n",
      "Difference in logits for target label: -0.1687335968017578\n",
      "==================================================\n",
      "Image path is /data2/ty45972_data2/taming-transformers/datasets/imagenet_VQGAN_generated/83/001304.png\n",
      "Original logits for target label: 9.848310470581055\n",
      "Masked logits for target label: 9.790656089782715\n",
      "Difference in logits for target label: 0.057654380798339844\n",
      "==================================================\n",
      "Image path is /data2/ty45972_data2/taming-transformers/datasets/imagenet_VQGAN_generated/83/001305.png\n",
      "Original logits for target label: 7.251029014587402\n",
      "Masked logits for target label: 8.895857810974121\n",
      "Difference in logits for target label: -1.6448287963867188\n",
      "==================================================\n",
      "Image path is /data2/ty45972_data2/taming-transformers/datasets/imagenet_VQGAN_generated/83/001306.png\n",
      "Original logits for target label: 8.98872184753418\n",
      "Masked logits for target label: 8.5968599319458\n",
      "Difference in logits for target label: 0.3918619155883789\n",
      "==================================================\n",
      "Image path is /data2/ty45972_data2/taming-transformers/datasets/imagenet_VQGAN_generated/83/001307.png\n",
      "Original logits for target label: 8.832515716552734\n",
      "Masked logits for target label: 2.492093563079834\n",
      "Difference in logits for target label: 6.3404221534729\n",
      "==================================================\n",
      "Image path is /data2/ty45972_data2/taming-transformers/datasets/imagenet_VQGAN_generated/83/001308.png\n",
      "Original logits for target label: 9.22626781463623\n",
      "Masked logits for target label: 9.289362907409668\n",
      "Difference in logits for target label: -0.0630950927734375\n",
      "==================================================\n",
      "Image path is /data2/ty45972_data2/taming-transformers/datasets/imagenet_VQGAN_generated/83/001309.png\n",
      "Original logits for target label: 8.328529357910156\n",
      "Masked logits for target label: 2.9540884494781494\n",
      "Difference in logits for target label: 5.374440908432007\n",
      "==================================================\n",
      "Image path is /data2/ty45972_data2/taming-transformers/datasets/imagenet_VQGAN_generated/83/001310.png\n",
      "Original logits for target label: 8.852380752563477\n",
      "Masked logits for target label: 8.258203506469727\n",
      "Difference in logits for target label: 0.59417724609375\n",
      "==================================================\n",
      "Image path is /data2/ty45972_data2/taming-transformers/datasets/imagenet_VQGAN_generated/83/001311.png\n",
      "Original logits for target label: 8.98996639251709\n",
      "Masked logits for target label: 8.784710884094238\n",
      "Difference in logits for target label: 0.20525550842285156\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import pickle\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 加载预训练的ResNet50模型\n",
    "model = torchvision.models.vit_b_32(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# 2. 定义图像预处理步骤（调整为224x224尺寸）\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# 图像预处理函数\n",
    "def preprocess_image(image):\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)  # 添加批次维度\n",
    "    return input_batch\n",
    "\n",
    "# 加载top N tokens的函数\n",
    "def load_top_tokens_baseline(input_csv, top_n):\n",
    "    tokens = []\n",
    "    with open(input_csv, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            token = int(row['Token'])\n",
    "            count = int(row['Count'])\n",
    "            tokens.append((token, count))\n",
    "    \n",
    "    tokens.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_n_tokens = [token for token, _ in tokens[:top_n]]\n",
    "    \n",
    "    return top_n_tokens\n",
    "\n",
    "# 加载token列表\n",
    "def load_top_tokens(csv_path, top_n, token_number):\n",
    "    target_token_list = []\n",
    "    with open(csv_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        in_top_n_section = False\n",
    "        current_row = 0\n",
    "\n",
    "        for row in reader:\n",
    "            if f\"Top {top_n} Tokens\" in row:\n",
    "                in_top_n_section = True\n",
    "                next(reader)\n",
    "                current_row = 0\n",
    "                continue\n",
    "\n",
    "            if in_top_n_section:\n",
    "                if \"Top\" in row[0] or current_row == token_number:\n",
    "                    break\n",
    "                token = int(row[0])\n",
    "                target_token_list.append(token)\n",
    "                current_row += 1\n",
    "\n",
    "    return target_token_list\n",
    "\n",
    "# 定义路径和目标label\n",
    "target_label = 83\n",
    "csv_path = f\"/data2/ty45972_data2/taming-transformers/codebook_explanation_classification/results/Explanation/generated_data/label/Net1/label_activation_statistics/label_{target_label}.csv\"\n",
    "test_csv = f\"/data2/ty45972_data2/taming-transformers/codebook_explanation_classification/datasets/VQGAN_16384_generated_new/test_embeddings.csv\"\n",
    "image_base_path = '/data2/ty45972_data2/taming-transformers/datasets/imagenet_VQGAN_generated/'\n",
    "baseline_path = f\"/data2/ty45972_data2/taming-transformers/codebook_explanation_classification/results/Explanation/baseline_statistics/label_{target_label}.csv\"\n",
    "\n",
    "# 加载token字典\n",
    "with open('/data2/ty45972_data2/taming-transformers/codebook_explanation_classification/datasets/VQGAN_16384_generated_new/test_token_indices.pkl', 'rb') as f:\n",
    "    token_dict = pickle.load(f)\n",
    "\n",
    "top_n = 20  # 查找前N个token\n",
    "token_num = 50  # 查找第1行的token及其文件列表\n",
    "\n",
    "# 加载tokens\n",
    "target_token_list = load_top_tokens(csv_path, top_n, token_num)\n",
    "target_token_list_baseline = load_top_tokens_baseline(baseline_path, token_num)\n",
    "print(f\"baseline token list is {target_token_list_baseline}\")\n",
    "\n",
    "if target_token_list:\n",
    "    print(f\"target token list is {len(target_token_list)}\")\n",
    "else:\n",
    "    print(\"Cannot find the specific token\")\n",
    "\n",
    "# 从test CSV加载文件列表\n",
    "npy_file_list = []\n",
    "with open(test_csv, 'r', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        filename = row[0]\n",
    "        label = int(row[1])\n",
    "        if label == target_label:\n",
    "            npy_file_list.append(filename)\n",
    "print(f\"npy_file_list is {len(npy_file_list)}\")\n",
    "\n",
    "# 定义图像网格\n",
    "grid_size = 16\n",
    "image_size = 256\n",
    "patch_size = image_size // grid_size\n",
    "\n",
    "# mask和对比logits函数\n",
    "def visualize_token_on_image_and_compare(npy_filename, token_dict, target_token_list):\n",
    "    subfolder, image_name = npy_filename.split('_')\n",
    "    image_name = image_name.replace('.npy', '.png')\n",
    "    image_path = os.path.join(image_base_path, subfolder, image_name)\n",
    "    \n",
    "    print(f\"Image path is {image_path}\")\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image {image_path} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    token_list = token_dict.get(npy_filename)\n",
    "    \n",
    "    if token_list is None:\n",
    "        print(f\"No token list found for {npy_filename}.\")\n",
    "        return\n",
    "    \n",
    "    token_positions = [i for i, token in enumerate(token_list) if token in target_token_list]\n",
    "\n",
    "    # 原始图像预测logits\n",
    "    input_batch = preprocess_image(image).to(device)\n",
    "    with torch.no_grad():\n",
    "        original_output = model(input_batch)\n",
    "    original_logits = original_output[0, target_label].item()\n",
    "    print(f\"Original logits for target label: {original_logits}\")\n",
    "    \n",
    "    # Mask token区域并预测logits\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for token_position in token_positions:\n",
    "        row = token_position // grid_size\n",
    "        col = token_position % grid_size\n",
    "        left = col * patch_size\n",
    "        upper = row * patch_size\n",
    "        right = left + patch_size\n",
    "        lower = upper + patch_size\n",
    "        draw.rectangle([left, upper, right, lower], fill=(0, 0, 0))\n",
    "    \n",
    "    masked_batch = preprocess_image(image).to(device)\n",
    "    with torch.no_grad():\n",
    "        masked_output = model(masked_batch)\n",
    "    masked_logits = masked_output[0, target_label].item()\n",
    "    print(f\"Masked logits for target label: {masked_logits}\")\n",
    "\n",
    "    # 对比logits差异\n",
    "    logits_diff = original_logits - masked_logits\n",
    "    print(f\"Difference in logits for target label: {logits_diff}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# 遍历所有文件，进行可视化和logits对比\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for i, npy_file in enumerate(npy_file_list):\n",
    "    visualize_token_on_image_and_compare(npy_file, token_dict, target_token_list)\n",
    "    if i > 10:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VQGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
